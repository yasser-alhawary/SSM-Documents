# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this
# software and associated documentation files (the "Software"), to deal in the Software
# without restriction, including without limitation the rights to use, copy, modify,
# merge, publish, distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
# PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#
---
description: |-
            ## Id
            AWSResilienceHub-MoveSQSMessagesBetweenQueuesSOP_2021-03-11

            ## Intent
            Moves messages from one queue to another. Can be used to restore messages from Dead Letter queue back to main operation one or visa versa

            ## Type
            SOP

            ## Risk
            Medium

            ## Requirements
              * Source SQS Queue, with queue policy that allows sendMessage, recieveMessage and deleteMessage actions
              * Target SQS Queue, with queue policy that allows sendMessage, recieveMessage and deleteMessage actions

            ## Permissions required for AutomationAssumeRole
              * sqs:SendMessage
              * sqs:DeleteMessage
              * sqs:ReceiveMessage
              * sqs:GetQueueAttributes

            ##### In case queues are encrypted with a KMS key
              * kms:GenerateDataKey
              * kms:Decrypt
              * kms:Encrypt

            ##### To write logs to CloudWatch
              * logs:CreateLogStream
              * logs:PutLogEvents
              * logs:DescribeLogGroups
              * logs:DescribeLogStreams

            ## Cancellation behavior
            Fail

            ## Inputs
            ### (Required) AutomationAssumeRole
              * type: String
              * description: ARN of the IAM role with permissions listed above

            ### (Required) SourceQueueUrl
              * type: String
              * description: The URL of the source SQS Queue

            ### (Required) TargetQueueUrl
              * type: String
              * description: The URL of the target SQS Queue

            ### (Required) NumberOfMessagesToTransfer
              * type: Integer
              * description: The number of messages to be sent

            ### (Optional) MessagesTransferBatchSize
              * type: Integer
              * description: The number of messages that going to be transferred per batch. Maximum is 10
              * default: 10

            ### (Optional) ForceExecution
              * type: Boolean
              * description: (Optional) If True, validation of input parameters will be skipped
              * default: false

            ## Details
            This document reads the specified number of messages from the source queue, attempts to send them to the
            target queue, and then deletes sent messages from the source queue.
            Re-executing this document can lead to duplicate messages in the target queue if the message was not successfully transferred during the previous attempt.
            Number of messages, latency (e.g. cross-region transfer) and message size can lead to a significant time for transferring messages. Since there is a hard cap of 10 minutes for executeScript action, the script would automatically stop after 9 minutes and report on how many messages have been sent so far.
            Validates if given 'Source' and 'Target' queues are different types (FIFO, Standard). If so, the script will throw an error. Customers can suppress the validation by passing `ForceExecution` parameter.
            Bear in mind that in case of FIFO queue, messages might be re-ordered while being transferred to the target one.

            ## Steps executed in normal flow
              * RecordStartTime
              * TransferMessages
              * OutputRecoveryTime

            ## Outputs
            ### OutputRecoveryTime.RecoveryTime
              * type: Integer
              * description: SOP execution time in seconds

            ### TransferMessages.TimeElapsed
              * type: String
              * description: Time in seconds elapsed during message transfer

            ### TransferMessages.NumberOfMessagesTransferredToTarget
              * type: Integer
              * description: Number of messages transfered to target

            ### TransferMessages.NumberOfMessagesFailedToSendToTarget
              * type: Integer
              * description: Number of messages failed to be moved to target

            ### TransferMessages.NumberOfMessagesFailedToDeleteFromSource
              * type: Integer
              * description: Number of messages failed to be removed from source after transfer
schemaVersion: "0.3"
assumeRole: "{{AutomationAssumeRole}}"
parameters:
  SourceQueueUrl:
    type: String
    description: (Required) The URL of the source SQS Queue.
  TargetQueueUrl:
    type: String
    description: (Required) The URL of the target SQS Queue.
  NumberOfMessagesToTransfer:
    type: Integer
    description: (Required) The number of messages to be sent.
  MessagesTransferBatchSize:
    type: Integer
    description: (Optional) The number of messages that going to be transferred per batch. Maximum is 10
    default: 10
  ForceExecution:
    type: Boolean
    description: (Optional) Specifies whether to execute the Automation without validation of input parameters
    default: false
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
outputs:
  - "OutputRecoveryTime.RecoveryTime"
  - "TransferMessages.NumberOfMessagesTransferredToTarget"
  - "TransferMessages.NumberOfMessagesFailedToSendToTarget"
  - "TransferMessages.NumberOfMessagesFailedToDeleteFromSource"
  - "TransferMessages.TimeElapsed"
mainSteps:
  - name: RecordStartTime
    description: 'Start recording execution time'
    action: 'aws:executeScript'
    outputs:
      - Name: StartTime
        Selector: $.Payload
        Type: String
    inputs:
      Runtime: python3.8
      Handler: start_time
      Script: |-
        import boto3
        import logging
        from datetime import datetime, timezone
        import time
        
        from botocore.exceptions import ClientError
        from dateutil import parser
        
        logger = logging.getLogger()
        logger.setLevel(logging.INFO)
        
        

        def start_time(events, context):
            return datetime.now(timezone.utc).isoformat()
        
        


  - name: TransferMessages
    description: >-
      Execute script that reads messages from source source, sends them to target source, confirms that messages were
      received and removes them from source afterwards. Returns the number of messages moved, failed, and failed to be
      removed from source but transferred to target.
    action: aws:executeScript
    outputs:
      - Name: "NumberOfMessagesTransferredToTarget"
        Selector: "$.Payload.NumberOfMessagesTransferredToTarget"
        Type: Integer
      - Name: "NumberOfMessagesFailedToSendToTarget"
        Selector: "$.Payload.NumberOfMessagesFailedToSendToTarget"
        Type: Integer
      - Name: "NumberOfMessagesFailedToDeleteFromSource"
        Selector: "$.Payload.NumberOfMessagesFailedToDeleteFromSource"
        Type: Integer
      - Name: "TimeElapsed"
        Selector: "$.Payload.TimeElapsed"
        Type: String
    inputs:
      Runtime: "python3.7"
      Handler: "transfer_messages"
      InputPayload:
        SourceQueueUrl: '{{SourceQueueUrl}}'
        TargetQueueUrl: '{{TargetQueueUrl}}'
        NumberOfMessagesToTransfer: '{{NumberOfMessagesToTransfer}}'
        MessagesTransferBatchSize: '{{MessagesTransferBatchSize}}'
        ForceExecution: '{{ForceExecution}}'
      Script: |-
        import json
        import logging
        import time
        import uuid
        import boto3
        import random
        from datetime import datetime
        from typing import List, Callable, Optional
        from botocore.exceptions import ClientError
        from botocore.config import Config
        
        logger = logging.getLogger()
        logger.setLevel(logging.INFO)
        
        


        def transform_messages(messages: List[dict], transform_message_function: Callable) -> List[dict]:
            """
            Transform all messages
            :param messages: messages to transform
            :param transform_message_function: method to transform one message
            :return: transformed messages
            """
            transformed_messages: List[dict] = []
            for message in messages:
                message = transform_message_function(message)
                transformed_messages.append(message)
            return transformed_messages
        
        

        def transform_message_and_attributes(message: dict) -> dict:
            """
            General method to transform one message
            :param message: Message to transform
            :return: transformed message
            """
            message_to_send = {'Id': message.get('MessageId'),
                               'MessageBody': message.get('Body')}
            if message.get('MessageAttributes') is not None:
                message_to_send['MessageAttributes'] = message.get('MessageAttributes')
            attributes = message.get('Attributes')
            if attributes is not None:
                aws_trace_header = attributes.get('AWSTraceHeader')
                if aws_trace_header is not None:
                    message_to_send['MessageSystemAttributes'] = 
                        {'AWSTraceHeader': {'StringValue': aws_trace_header,
                                            'DataType': 'String'}}
            return message_to_send
        
        

        def transform_message_from_fifo_to_fifo(message: dict) -> dict:
            """
            Transform one message from FIFO to FIFO
            :param message: Message to transform
            :return: transformed message
            """
            message_to_send = transform_message_and_attributes(message)
        
            attributes = message.get('Attributes')
            if attributes is not None:
                message_to_send['MessageDeduplicationId'] = attributes.get('MessageDeduplicationId')
                message_to_send['MessageGroupId'] = str(attributes.get('MessageGroupId'))
            return message_to_send
        
        

        def transform_message_from_standard_to_fifo(message: dict) -> dict:
            """
            Transform one message from Standard to FIFO
            :param message: Message to transform
            :return: transformed message
            """
            message_to_send = transform_message_and_attributes(message)
            message_to_send['MessageDeduplicationId'] = str(uuid.uuid4())
            message_to_send['MessageGroupId'] = str(uuid.uuid4())
            return message_to_send
        
        

        def send_messages(messages_to_send: List[dict], target_queue_url: str) -> dict:
            """
            Send messages by batch operation
            :param messages_to_send: messages to send
            :param target_queue_url: URL of the queue to send
            :return: response of send_message_batch method
            """
            config = Config(retries={'max_attempts': 20, 'mode': 'standard'})
            sqs_client = boto3.client("sqs", config=config)
            send_message_batch_response: dict = sqs_client.send_message_batch(QueueUrl=target_queue_url,
                                                                              Entries=messages_to_send)
            return send_message_batch_response
        
        

        def receive_messages(source_queue_url: str, messages_transfer_batch_size: int, wait_timeout: int = 0) -> 
                Optional[List[dict]]:
            """
            Receive messages
            :param wait_timeout: The duration i seconds for which the call waits for a message to arrive in the queue
            :param messages_transfer_batch_size: how many messages to receive
            :param source_queue_url:  URL of the queue where from messages are received
            :return: response of receive_message method
            """
            config = Config(retries={'max_attempts': 20, 'mode': 'standard'})
            sqs_client = boto3.client("sqs", config=config)
            receive_message_response: dict = 
                sqs_client.receive_message(QueueUrl=source_queue_url,
                                           MaxNumberOfMessages=messages_transfer_batch_size,
                                           WaitTimeSeconds=wait_timeout,
                                           MessageAttributeNames=['All'],
                                           AttributeNames=['All'])
            return receive_message_response.get('Messages')
        
        

        def transfer_messages(events: dict, context: dict) -> dict:
            """
            Move received_messages from one queue to another.
            """
            if "SourceQueueUrl" not in events or "TargetQueueUrl" not in events 
                    or "NumberOfMessagesToTransfer" not in events or "ForceExecution" not in events 
                    or "MessagesTransferBatchSize" not in events:
                raise KeyError("Requires SourceQueueUrl and TargetQueueUrl and NumberOfMessagesToTransfer and "
                               "MessagesTransferBatchSize and ForceExecution in events")
            config = Config(retries={'max_attempts': 20, 'mode': 'standard'})
            sqs_client = boto3.client("sqs", config=config)
            start_execution = datetime.utcnow()
        
            source_queue_url: str = events['SourceQueueUrl']
            target_queue_url: str = events['TargetQueueUrl']
            force_execution: bool = bool(events['ForceExecution'])
            number_of_messages_to_transfer: int = int(events['NumberOfMessagesToTransfer'])
            messages_transfer_batch_size: int = int(events['MessagesTransferBatchSize'])
        
            is_source_queue_fifo: bool = is_queue_fifo(source_queue_url, sqs_client)
            is_target_queue_fifo: bool = is_queue_fifo(target_queue_url, sqs_client)
        
            if force_execution is False and is_source_queue_fifo != is_target_queue_fifo:
                raise ValueError(f'The source queue and target queue have different types when ForceExecution '
                                 f'parameter is {force_execution}: ')
        
            number_of_messages_transferred_to_target = 0
            number_of_messages_failed_to_send_to_target = 0
            number_of_messages_failed_to_delete_from_source = 0
            start = now = int(time.time())
            max_duration_seconds = 9 * 60
            loop_count = 1
            number_of_messages_received_from_source = 0
        
            if number_of_messages_to_transfer == 0:
                return get_statistics(loop_count, now, number_of_messages_failed_to_delete_from_source,
                                      number_of_messages_failed_to_send_to_target,
                                      number_of_messages_transferred_to_target, source_queue_url, start,
                                      start_execution, max_duration_seconds)
        
            while number_of_messages_received_from_source < number_of_messages_to_transfer 
                    and (now - start) < max_duration_seconds:
                logger.debug(f'Entered into loop #{loop_count} '
                             f'with number_of_messages_transferred_to_target < number_of_messages_to_transfer = '
                             f'{number_of_messages_transferred_to_target} < {number_of_messages_to_transfer}, '
                             f'(now - start) < max_duration_seconds = {now - start} < {max_duration_seconds}')
        
                messages_transfer_batch_size_for_each_call = 
                    min((number_of_messages_to_transfer - number_of_messages_received_from_source),
                        messages_transfer_batch_size)
        
                received_messages: Optional[List[dict]] = receive_messages(
                    source_queue_url, messages_transfer_batch_size_for_each_call, 5
                )
                if not received_messages:
                    logger.debug('Received no messages from source, repeating')
                    now = int(time.time())
                    continue
        
                number_of_messages_received_from_source += len(received_messages)
        
                messages_to_send: List[dict] = []
                if is_source_queue_fifo and is_target_queue_fifo:  # If both queues are FIFO
                    messages_to_send = transform_messages(received_messages, transform_message_from_fifo_to_fifo)
                elif not is_source_queue_fifo and not is_target_queue_fifo:  # If both queues are standard
                    messages_to_send = transform_messages(received_messages, transform_message_and_attributes)
                elif is_source_queue_fifo and not is_target_queue_fifo:
                    messages_to_send = transform_messages(received_messages, transform_message_and_attributes)
                elif not is_source_queue_fifo and is_target_queue_fifo:
                    messages_to_send = transform_messages(received_messages, transform_message_from_standard_to_fifo)
        
                send_message_batch_response: dict = send_messages(messages_to_send, target_queue_url)
                successfully_sent_results = send_message_batch_response.get('Successful')
                if successfully_sent_results is not None:
                    successfully_sent_results_number = len(successfully_sent_results)
                    logger.info(f'Succeed to send {successfully_sent_results_number} message(-s) '
                                f'during the loop #{loop_count}: '
                                f'{successfully_sent_results}')
        
                    message_id_to_receipt_handle = {message.get('MessageId'): message.get('ReceiptHandle')
                                                    for message in received_messages}
                    delete_message_entries: List = [{'Id': result.get('Id'),
                                                     'ReceiptHandle': message_id_to_receipt_handle.get(result.get('Id'))}
                                                    for result in successfully_sent_results]
                    delete_message_batch_response: dict = sqs_client.delete_message_batch(QueueUrl=source_queue_url,
                                                                                          Entries=delete_message_entries)
                    failed_delete_messages: List[dict] = delete_message_batch_response.get('Failed')
                    if failed_delete_messages is not None:
                        failed_delete_messages_number = len(failed_delete_messages)
                        logger.info(f'Failed to delete {failed_delete_messages_number} message(-s) '
                                    f'during the loop #{loop_count}: '
                                    f'{failed_delete_messages}')
                        number_of_messages_failed_to_delete_from_source += failed_delete_messages_number
        
                    succeed_delete_messages = delete_message_batch_response.get('Successful')
                    if succeed_delete_messages is not None:
                        logger.info(f'Succeed to delete {len(succeed_delete_messages)} message(-s) '
                                    f'during the loop #{loop_count}: '
                                    f'{succeed_delete_messages}')
                        number_of_messages_transferred_to_target += len(succeed_delete_messages)
        
                failed_send_results: dict = send_message_batch_response.get('Failed')
                if failed_send_results is not None:
                    failed_send_results_number = len(failed_send_results)
                    logger.info(f'Failed to send {failed_send_results_number} message(-s) '
                                f'during the loop #{loop_count}: '
                                f'{failed_send_results}')
                    number_of_messages_failed_to_send_to_target += failed_send_results_number
        
                now = int(time.time())
                loop_count += 1
        
            return get_statistics(loop_count, now, number_of_messages_failed_to_delete_from_source,
                                  number_of_messages_failed_to_send_to_target,
                                  number_of_messages_transferred_to_target, source_queue_url, start,
                                  start_execution, max_duration_seconds)
        
        

        def get_statistics(loop_count: int, now, number_of_messages_failed_to_delete_from_source: int,
                           number_of_messages_failed_to_send_to_target: int,
                           number_of_messages_transferred_to_target: int,
                           source_queue_url: str, start, start_execution, max_duration_seconds: int):
            statistics = {'NumberOfMessagesTransferredToTarget': number_of_messages_transferred_to_target,
                          'NumberOfMessagesFailedToDeleteFromSource':
                              number_of_messages_failed_to_delete_from_source,
                          'NumberOfMessagesFailedToSendToTarget': number_of_messages_failed_to_send_to_target,
                          'TimeElapsed': str((datetime.utcnow() - start_execution).total_seconds())}
            logger.info(f'Quiting the loop to receive the messages from source queue with URL = {source_queue_url} '
                        f'because there are no messages received during the loop #{loop_count} and {(now - start)} '
                        f'second(-s) of script's execution or the maximum time in {max_duration_seconds} was elapsed. '
                        f'Statistics: {statistics}')
            return statistics
        
        

        def is_queue_fifo(queue_url: str, sqs_client):
            try:
                sqs_client.get_queue_attributes(QueueUrl=queue_url, AttributeNames=['FifoQueue'])
            except ClientError as e:
                if e.response['Error']['Code'] == 'InvalidAttributeName':
                    logger.info(f'The queue with url = {queue_url} is not a FIFO')
                    return False
                else:
                    logger.error(e)
                    raise e
            return True
        
        


  - name: OutputRecoveryTime
    description: 'Calculate execution time'
    action: 'aws:executeScript'
    outputs:
      - Name: RecoveryTime
        Selector: $.Payload
        Type: Integer
    inputs:
      Runtime: python3.8
      Handler: recovery_time
      Script: |-
        import boto3
        import logging
        from datetime import datetime, timezone
        import time
        
        from botocore.exceptions import ClientError
        from dateutil import parser
        
        logger = logging.getLogger()
        logger.setLevel(logging.INFO)
        
        

        def recovery_time(events, context):
            return (datetime.now(timezone.utc) - parser.parse(events['StartTime'])).seconds
        
        

      InputPayload:
        StartTime: '{{ RecordStartTime.StartTime }}'
