description: "The AWSSupport-EnableVPCFlowLogs runbook allows you to automate the
   creation of Amazon Virtual Private Cloud (Amazon VPC) flow logs for the following
   type of resources: subnets, network interfaces and/or VPCs in your AWS account.
   If you create a flow log for a subnet or VPC, each network interface in that subnet
   or VPC is monitored. Flow log data is published to the Amazon CloudWatch Logs
   or Amazon Simple Storage Service (Amazon S3) you choose. After you've created
   a flow log, you can retrieve and view its data in the chosen destination. For
   more information, see [VPC Flow Logs](https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html)

  
### Additional Information
VPC Flow Logs is a feature that enables you to capture
   network internet protocol (IP) traffic flow going to and from network interfaces
   in your VPC/subnet. The data can be used for investigating and troubleshooting
   connectivity issues.
### Important
The creation of VPC Flow Logs will add extra
   costs for storing the logs both in S3 and CloudWatch Logs. For more information
   see [Flow logs pricing]( https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html#flow-logs-pricing)

  
``Note: If you don’t specify a value for LogGroupName and LogDestinationARN is
   'cloud-watch-logs', the runbook tries to create a new CloudWatch Log Group with
   the name ‘AWSSupport-EnableVPCFlowLogs-<automation:EXECUTION_ID>’. When the automation
   creates the new Log Group, it sets the number of days to retain the log data to
   14 days.``"
schemaVersion: "0.3"
assumeRole: "{{ AutomationAssumeRole }}"
outputs:
- "CreateFlowLogs.message"
parameters:
  ResourceIds:
    type: "StringList"
    allowedPattern: "(vpc-[a-z0-9]{8,17}|eni-[a-z0-9]{8,17}|subnet-[a-z0-9]{8,17})"
    description: "(Required) Comma separated list with of the ID(s) of the subnet,
       network interface, or VPC for which you want to create a flow log (e.g: subnet-123a351e)"
  TrafficType:
    type: "String"
    default: "ALL"
    description: "(Required) The type of traffic to log. You can log traffic that
       the resource accepts or rejects, or all traffic."
    allowedValues:
    - "ACCEPT"
    - "REJECT"
    - "ALL"
  LogDestinationType:
    type: "String"
    default: "cloud-watch-logs"
    description: "(Required) Specifies the destination type to which the flow log
       data is to be published. Flow log data can be published to CloudWatch Logs
       or Amazon S3. To publish flow log data to CloudWatch Logs, specify cloud-watch-logs.
       To publish flow log data to Amazon S3, specify s3."
    allowedValues:
    - "cloud-watch-logs"
    - "s3"
  DeliverLogsPermissionArn:
    type: "String"
    default: ""
    description: "(Depends on LogDestinationType) The ARN for the IAM role that permits
       Amazon EC2 to publish flow logs to a CloudWatch Logs log group in your account.
       If you specify *LogDestinationType* as 's3', do not specify *DeliverLogsPermissionArn*
       or *LogGroupName*."
    allowedPattern: "(^arn:(aws[a-zA-Z-]*)?:iam::d{12}:role/[w+=,.@-]+$)?"
  LogDestinationARN:
    type: "String"
    default: ""
    description: "(Optional) Specifies the destination to which the flow log data
       is to be published. Flow log data can be published to a CloudWatch Logs log
       group or an Amazon S3 bucket. The value specified for this parameter depends
       on the value specified for LogDestinationType. If LogDestinationType is 'cloud-watch-logs',
       specify the ARN of the CloudWatch Logs log group. Otherwise specify the ARN
       of the Amazon S3 bucket. You can also specify a subfolder in the bucket: bucket_ARN/subfolder_name/.
       *Note*: `if nothing is specified, the automation will create a CloudWatch
       Log Group, stream and the IAM role to put data in it on behalf of VPC Flow
       Logs.`"
    allowedPattern: "(^arn:(aws[a-zA-Z-]*)?:(logs|s3):([w+-]+)?:(d{12})?:[w+-]+(:|
      /)?[w+=,.@-:/*]+$)?"
  LogFormat:
    type: "String"
    default: "${version} ${account-id} ${interface-id} ${srcaddr} ${dstaddr} ${srcport}
       ${dstport} ${protocol} ${packets} ${bytes} ${start} ${end} ${action} ${log-status}"
    description: "(Optional) The fields to include in the flow log record, in the
       order in which they should appear. For a list of available fields, see Flow
       Log Records. If you omit this parameter, the flow log is created using the
       default format. If you specify this parameter, you must specify at least one
       field."
    allowedPattern: "(${[a-z-s?]+}s?)+"
  LogGroupName:
    type: "String"
    description: "(Depends on LogDestinationType) The name of the CloudWatch Logs
       log group you want to publish flow log data to. This parameter is required
       only if the parameter *LogDestinationType* is set to cloud-watch-logs"
    default: ""
    allowedPattern: "^$|[.-_/#A-Za-z0-9]+"
  AutomationAssumeRole:
    type: "String"
    default: ""
    description: "(Optional) The ARN of the role that allows the Automation runbook
       to perform the actions on your behalf. If no role is specified, Systems Manager
       Automation uses your current IAM user permissions context to execute this
       runbook."
    allowedPattern: "(^arn:(aws[a-zA-Z-]*)?:iam::d{12}:role/[w+=,.@-]+$)?"
mainSteps:
- name: "CheckDestinationType"
  action: "aws:branch"
  inputs:
    Choices:
    - NextStep: "CheckLogDestination"
      Variable: "{{ LogDestinationType }}"
      Contains: "cloud-watch-logs"
    - NextStep: "CreateFlowLogs"
      Variable: "{{ LogDestinationType }}"
      Contains: "s3"
  description: "Checks the parameter: 'LogDestinationType' if it's "cloud-watch-logs"
    
"
- name: "CheckLogDestination"
  action: "aws:executeScript"
  inputs:
    Runtime: "python3.8"
    Handler: "script_handler"
    InputPayload:
      LogDestinationType: "{{ LogDestinationType }}"
      DeliverLogsPermissionArn: "{{ DeliverLogsPermissionArn }}"
      LogDestinationARN: "{{ LogDestinationARN }}"
    Script: "def script_handler(events, context):
    import boto3
    import time

          import re
    
    RETENTION_DAYS = 14
    ACCOUNT_ID = context["global:ACCOUNT_ID"
      ]
    region = context["global:REGION"]
    ExecutionId = context["automation:EXECUTION_ID"
      ]
    LogDestinationType = events["LogDestinationType"]
    DeliverLogsPermissionArn
       = events["DeliverLogsPermissionArn"]
    LogDestinationARN = events["
      LogDestinationARN"]
    
    if LogDestinationType == 'cloud-watch-logs':

              logs = boto3.client('logs')
        iam = boto3.client('iam')
  
            if LogDestinationARN == '':
            try:
                response
       = logs.create_log_group(
                    logGroupName='AWSSupport-EnableVPCFlowLogs-'+ExecutionId,

                          tags={
                        'Author': 'Created by AWSSupport-EnableVPCFlowLogs
       automation'
                    }
                )
                if
       response['ResponseMetadata']["HTTPStatusCode"] == 200:
               
           time.sleep(3)
                    response = logs.put_retention_policy(

                              logGroupName='AWSSupport-EnableVPCFlowLogs-'+ExecutionId,

                              retentionInDays=RETENTION_DAYS
                  
        )
                    LogDestinationARN = 'arn:aws:logs:'+region+':'+ACCOUNT_ID+':log-group:AWSSupport-EnableVPCFlowLogs-'+ExecutionId+':*'

                  except Exception as e:
                if "ResourceAlreadyExistsException"
       in str(e):
                    LogDestinationARN = 'arn:aws:logs:'+region+':'+ACCOUNT_ID+':log-group:AWSSupport-EnableVPCFlowLogs-'+ExecutionId+':*'

                      else:
                    raise Exception("Something went
       wrong on Log Group Creation, please check: "+"
"+str(e))
        if
       DeliverLogsPermissionArn == '':

            ## Create the role
      
            try: 
                response = iam.create_role(
                
          RoleName='AWSSupportCreateFlowLogsRole',
                    AssumeRolePolicyDocument="
      {
  "Version": "2012-10-17",
  "Statement": [
    {
      n      "Sid": "",
      "Effect": "Allow",
    
        "Principal": {
        "Service": "vpc-flow-logs.amazonaws.com
      "
      },
      "Action": "sts:AssumeRole"
    }
  ]
      n}",
                    Tags=[
                        {
             
                     'Key': 'Author',
                            'Value': 'Created
       by AWSSupport-EnableVPCFlowLogs automation'
                        },

                          ]
                )
                if response["ResponseMetadata"
      ]["HTTPStatusCode"] == 200:
                    DeliverLogsPermissionArn
       = response["Role"]["Arn"]
            except Exception as e:
      
                if "EntityAlreadyExists" in str(e):
                    DeliverLogsPermissionArn
       = 'arn:aws:iam::'+ACCOUNT_ID+':role/AWSSupportCreateFlowLogsRole'
      
                else:
                    response = logs.delete_log_group(
  
                            logGroupName='AWSSupport-EnableVPCFlowLogs-'+ExecutionId

                          )
                    raise Exception("Something went
       wrong, please check: "+"
"+str(e))
            ## Create and attach
       policy
            try: 
                time.sleep(3)
               
       response = iam.put_role_policy(
                    RoleName='AWSSupportCreateFlowLogsRole',

                          PolicyName='AWSSupportCreateFlowLogsPolicy',
        
                  PolicyDocument="{
    "Version": "2012-10-17",
      n    "Statement": [
        {
            "Action": [
   
                   "logs:CreateLogGroup",
                "logs:CreateLogStream
      ",
                "logs:PutLogEvents",
                "logs:DescribeLogGroups
      ",
                "logs:DescribeLogStreams"
            ],
  
                "Effect": "Allow",
            "Resource": 
      "*"
        }
    ]
}",
                )
            except Exception
       as e:
                    response = iam.delete_role(
                 
             RoleName='AWSSupportCreateFlowLogsRole'
                    )
   
                       response = logs.delete_log_group(
                      
        logGroupName='AWSSupport-EnableVPCFlowLogs-'+ExecutionId
              
            )
                    raise Exception("Something went wrong, please
       check: "+"
"+str(e))
        else:
            try:
             
         response = iam.get_role(RoleName=re.sub(r'arn:(aws[a-zA-Z-]*)?:iam::d{12}:role
      /', '', DeliverLogsPermissionArn))
            except Exception as e:
   
                   raise Exception("Identity Doesn't Exist in this account 
"
      +str(e))
    return    
"
  description: "Checks the LogDestinationARN parameter and creates a new CloudWatch
     Log group and the IAM role to put data in it."
  isCritical: true
  timeoutSeconds: 30
  isEnd: false
  nextStep: "CreateFlowLogs"
- name: "CreateFlowLogs"
  description: "Creates the flow logs on the selected destination."
  action: "aws:executeScript"
  timeoutSeconds: 180
  onFailure: "Abort"
  onCancel: "Abort"
  isCritical: true
  inputs:
    Runtime: "python3.8"
    Handler: "script_handler"
    InputPayload:
      ResourceIds: "{{ ResourceIds }}"
      TrafficType: "{{ TrafficType }}"
      LogDestinationType: "{{ LogDestinationType }}"
      DeliverLogsPermissionArn: "{{ DeliverLogsPermissionArn }}"
      LogDestinationARN: "{{ LogDestinationARN }}"
      LogFormat: "{{ LogFormat }}"
      LogGroupName: "{{ LogGroupName }}"
    Script: "def script_handler(events, context):
    import boto3
    import time

          import re
    
    def get_flow_logs_id(flow):
        if flow['FlowLogIds'][0]
       != '':
            return flow['FlowLogIds'][0]

    def rollback(output,
       ExecutionId):
        flow_logs_ids = list(map(get_flow_logs_id, output))

              try:
            logs = boto3.client('logs')
            iam = boto3.client('iam')

                  response = logs.delete_log_group(
                logGroupName='AWSSupport-EnableVPCFlowLogs-'+ExecutionId

                  )
            response = iam.delete_role(
                RoleName='AWSSupportCreateFlowLogsRole'

                  )
        except Exception as e:
            pass
        try:

                  ec2 = boto3.client('ec2')
            
            response =
       ec2.delete_flow_logs(
                FlowLogIds=flow_logs_ids
        
          )
            return response["HTTPStatusCode"]
        except Exception
       as e:
            pass

    ACCOUNT_ID = context["global:ACCOUNT_ID"
      ]
    region = context["global:REGION"]
    ExecutionId = context["automation:EXECUTION_ID"
      ]
    # @Parameters
    ResourceIds = events["ResourceIds"]
    TrafficType
       = events["TrafficType"]
    LogDestinationType = events["LogDestinationType"
      ]
    DeliverLogsPermissionArn = events["DeliverLogsPermissionArn"]
   
       LogDestinationARN = events["LogDestinationARN"]
    LogFormat = events["
      LogFormat"]
    LogGroupName = events["LogGroupName"]
    ec2 = boto3.client('ec2')

          
    # @ Input Validation
    output = []
    s3 = boto3.client('s3')

          if LogDestinationType == 'cloud-watch-logs':
        logs = boto3.client('logs')

              iam = boto3.client('iam')
        if LogDestinationARN == '':
  
                LogDestinationARN = 'arn:aws:logs:'+region+':'+ACCOUNT_ID+':log-group:AWSSupport-EnableVPCFlowLogs-'+ExecutionId+':*'

              if DeliverLogsPermissionArn == '':
           DeliverLogsPermissionArn
       = 'arn:aws:iam::'+ACCOUNT_ID+':role/AWSSupportCreateFlowLogsRole'
    else:

              try:
            BucketName = re.sub(r'arn:(aws[a-zA-Z-]*)?:(logs|s3):([
      w+-]+)?:(d{12})?:|(/.*)?', '', LogDestinationARN)
            
  
                response = s3.get_bucket_acl(Bucket=BucketName)
        except Exception
       as e:
            raise Exception("S3 Bucket destination not valid: 
"
      +str(e))

# @ Flowlogs creation
    for ResourceId in ResourceIds:
    
          ResourceType = ''
        message = ''
        if "vpc" in ResourceId:

                  ResourceType = 'VPC'
        if "eni" in ResourceId:
     
             ResourceType = 'NetworkInterface'
        if "subnet" in ResourceId:

                  ResourceType = 'Subnet'
        try:
            if LogDestinationType
       == 'cloud-watch-logs':
                if LogGroupName == '':
         
                 response = ec2.create_flow_logs(DeliverLogsPermissionArn=DeliverLogsPermissionArn,

                              ResourceIds=[ResourceId],
                       
       ResourceType=ResourceType,
                        TrafficType=TrafficType,

                              LogDestinationType=LogDestinationType,
          
                    LogDestination=LogDestinationARN,
                        LogFormat=LogFormat)

                          message = response
                else:
           
               response = ec2.create_flow_logs(DeliverLogsPermissionArn=DeliverLogsPermissionArn,

                              ResourceIds=[ResourceId],
                       
       ResourceType=ResourceType,
                        TrafficType=TrafficType,

                              LogDestinationType=LogDestinationType,
          
                    LogDestination=LogDestinationARN,
                        LogFormat=LogFormat,

                              LogGroupName=LogGroupName)
                    message
       = response
            else:
                response = ec2.create_flow_logs(

                              ResourceIds=[ResourceId],
                       
       ResourceType=ResourceType,
                        TrafficType=TrafficType,

                              LogDestinationType=LogDestinationType,
          
                    LogDestination=LogDestinationARN,
                        LogFormat=LogFormat)

                      message = response
                
# @ Exeptions and rollback
               
            if len(message["FlowLogIds"]) != 0:
            
          output.append({'FlowLogIds': message["FlowLogIds"], 'error': '', 'ResourceId':
       ResourceId, 'Destination': LogDestinationARN})   
            else:
   
                   if rollback(output, ExecutionId) == 200:
                   
       output.append({'FlowLogIds': [''], 'error': 'Rollback Successfull: all the
       pending flow logs have been cleaned', 'ResourceId': '', 'Destination': LogDestinationARN})

                      else:
                    output.append({'FlowLogIds': [''],
       'error': 'Rollback FAILED', 'ResourceId': '', 'Destination': LogDestinationARN})

                      output.append({'FlowLogIds': [''], 'error': message, 'ResourceId':
       ResourceId, 'Destination': LogDestinationARN})
                raise Exception("
      ClientError - " + str(output))

        except Exception as e:
        
          rollback_status = rollback(output, ExecutionId)
            if  rollback_status
       == 200:
                output.append({'FlowLogIds': [''], 'error': 'Rollback
       Successfull: all the pending flow logs have been cleaned', 'ResourceId': '',
       'Destination': LogDestinationARN})
            else: 
                output.append({'FlowLogIds':
       [''], 'error': 'Rollback FAILED: 
'+str(e), 'ResourceId': '', 'Destination':
       LogDestinationARN})
            output.append({'FlowLogIds': [''], 'error':
       e, 'ResourceId': ResourceId, 'Destination': LogDestinationARN})
        
          raise Exception("Something went wrong, please check: "+ResourceId + "
      
"+str(e)+"
"+str(output))
        
    return {"message": output}

      
"
  outputs:
  - Name: "message"
    Selector: "$.Payload.message"
    Type: "MapList"
  isEnd: true
